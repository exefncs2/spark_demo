<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">report.html</h1>
    <p>Report generated on 22-Jul-2024 at 00:08:47 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">10 tests took 00:00:04.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" disabled/>
            <span class="failed">0 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">10 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" />
            <span class="error">3 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.11.0&#34;, &#34;Platform&#34;: &#34;Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.34&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.2.2&#34;, &#34;pluggy&#34;: &#34;1.5.0&#34;}, &#34;Plugins&#34;: {&#34;cov&#34;: &#34;5.0.0&#34;, &#34;html&#34;: &#34;4.1.1&#34;, &#34;mock&#34;: &#34;3.14.0&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;}, &#34;JAVA_HOME&#34;: &#34;/usr/lib/jvm/java-17-openjdk-17.0.6.0.10-3.el9.x86_64&#34;}, &#34;tests&#34;: {&#34;S_ML/tests/test_psql_connector.py::test_query&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_psql_connector.py::test_query&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_psql_connector.py::test_query&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nresult: [{&amp;#x27;?column?&amp;#x27;: 1}]\n&#34;}], &#34;S_ML/tests/test_psql_connector.py::test_invalid_query&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_psql_connector.py::test_invalid_query&#34;, &#34;duration&#34;: &#34;56 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_psql_connector.py::test_invalid_query&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;56 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_rabbitmq_consumer.py::test_start_consuming&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_rabbitmq_consumer.py::test_start_consuming&#34;, &#34;duration&#34;: &#34;10 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_rabbitmq_consumer.py::test_start_consuming&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;10 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nWaiting for messages. To exit press CTRL+C\n&#34;}], &#34;S_ML/tests/test_rabbitmq_consumer.py::test_callback&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_rabbitmq_consumer.py::test_callback&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_rabbitmq_consumer.py::test_callback&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_redis_engine.py::test_set_and_get_value&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_redis_engine.py::test_set_and_get_value&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_redis_engine.py::test_set_and_get_value&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_redis_engine.py::test_set_value_with_ttl&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_redis_engine.py::test_set_value_with_ttl&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_redis_engine.py::test_set_value_with_ttl&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_redis_engine.py::test_hset_and_hget&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_redis_engine.py::test_hset_and_hget&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_redis_engine.py::test_hset_and_hget&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_redis_engine.py::test_hdel&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_redis_engine.py::test_hdel&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_redis_engine.py::test_hdel&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_redis_engine.py::test_exists&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_redis_engine.py::test_exists&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_redis_engine.py::test_exists&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_redis_engine.py::test_delete_value&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_redis_engine.py::test_delete_value&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_redis_engine.py::test_delete_value&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;S_ML/tests/test_spark_session.py::TestSparkEngine::test_spark_session&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_spark_session.py::TestSparkEngine::test_spark_session::setup&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_spark_session.py::TestSparkEngine::test_spark_session::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_spark_session.TestSparkEngine object at 0x7f824eef1210&amp;gt;\n\n    @pytest.fixture(scope=&amp;quot;class&amp;quot;)\n    def spark_engine(self):\n&amp;gt;       engine = SparkEngine()\n\nS_ML/tests/test_spark_session.py:9: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nS_ML/base/spark_engine.py:12: in __init__\n    .getOrCreate()\nspark_env/lib/python3.11/site-packages/pyspark/sql/session.py:497: in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\nspark_env/lib/python3.11/site-packages/pyspark/context.py:515: in getOrCreate\n    SparkContext(conf=conf or SparkConf())\nspark_env/lib/python3.11/site-packages/pyspark/context.py:201: in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\nspark_env/lib/python3.11/site-packages/pyspark/context.py:436: in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nconf = &amp;lt;pyspark.conf.SparkConf object at 0x7f824ac9d0d0&amp;gt;\npopen_kwargs = {&amp;#x27;env&amp;#x27;: {&amp;#x27;BASH_FUNC_which%%&amp;#x27;: &amp;#x27;() {  ( alias;\\n eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --rea...rk_demo/.coverage&amp;#x27;, ...}, &amp;#x27;preexec_fn&amp;#x27;: &amp;lt;function launch_gateway.&amp;lt;locals&amp;gt;.preexec_func at 0x7f824a88a020&amp;gt;, &amp;#x27;stdin&amp;#x27;: -1}\n\n    def launch_gateway(conf=None, popen_kwargs=None):\n        &amp;quot;&amp;quot;&amp;quot;\n        launch jvm gateway\n    \n        Parameters\n        ----------\n        conf : :py:class:`pyspark.SparkConf`\n            spark configuration passed to spark-submit\n        popen_kwargs : dict\n            Dictionary of kwargs to pass to Popen when spawning\n            the py4j JVM. This is a developer feature intended for use in\n            customizing how pyspark interacts with the py4j JVM (e.g., capturing\n            stdout/stderr).\n    \n        Returns\n        -------\n        ClientServer or JavaGateway\n        &amp;quot;&amp;quot;&amp;quot;\n        if &amp;quot;PYSPARK_GATEWAY_PORT&amp;quot; in os.environ:\n            gateway_port = int(os.environ[&amp;quot;PYSPARK_GATEWAY_PORT&amp;quot;])\n            gateway_secret = os.environ[&amp;quot;PYSPARK_GATEWAY_SECRET&amp;quot;]\n            # Process already exists\n            proc = None\n        else:\n            SPARK_HOME = _find_spark_home()\n            # Launch the Py4j gateway using Spark&amp;#x27;s run command so that we pick up the\n            # proper classpath and settings from spark-env.sh\n            on_windows = platform.system() == &amp;quot;Windows&amp;quot;\n            script = &amp;quot;./bin/spark-submit.cmd&amp;quot; if on_windows else &amp;quot;./bin/spark-submit&amp;quot;\n            command = [os.path.join(SPARK_HOME, script)]\n            if conf:\n                for k, v in conf.getAll():\n                    command += [&amp;quot;--conf&amp;quot;, &amp;quot;%s=%s&amp;quot; % (k, v)]\n            submit_args = os.environ.get(&amp;quot;PYSPARK_SUBMIT_ARGS&amp;quot;, &amp;quot;pyspark-shell&amp;quot;)\n            if os.environ.get(&amp;quot;SPARK_TESTING&amp;quot;):\n                submit_args = &amp;quot; &amp;quot;.join([&amp;quot;--conf spark.ui.enabled=false&amp;quot;, submit_args])\n            command = command + shlex.split(submit_args)\n    \n            # Create a temporary directory where the gateway server should write the connection\n            # information.\n            conn_info_dir = tempfile.mkdtemp()\n            try:\n                fd, conn_info_file = tempfile.mkstemp(dir=conn_info_dir)\n                os.close(fd)\n                os.unlink(conn_info_file)\n    \n                env = dict(os.environ)\n                env[&amp;quot;_PYSPARK_DRIVER_CONN_INFO_PATH&amp;quot;] = conn_info_file\n    \n                # Launch the Java gateway.\n                popen_kwargs = {} if popen_kwargs is None else popen_kwargs\n                # We open a pipe to stdin so that the Java gateway can die when the pipe is broken\n                popen_kwargs[&amp;quot;stdin&amp;quot;] = PIPE\n                # We always set the necessary environment variables.\n                popen_kwargs[&amp;quot;env&amp;quot;] = env\n                if not on_windows:\n                    # Don&amp;#x27;t send ctrl-c / SIGINT to the Java gateway:\n                    def preexec_func():\n                        signal.signal(signal.SIGINT, signal.SIG_IGN)\n    \n                    popen_kwargs[&amp;quot;preexec_fn&amp;quot;] = preexec_func\n                    proc = Popen(command, **popen_kwargs)\n                else:\n                    # preexec_fn not supported on Windows\n                    proc = Popen(command, **popen_kwargs)\n    \n                # Wait for the file to appear, or for the process to exit, whichever happens first.\n                while not proc.poll() and not os.path.isfile(conn_info_file):\n                    time.sleep(0.1)\n    \n                if not os.path.isfile(conn_info_file):\n&amp;gt;                   raise PySparkRuntimeError(\n                        error_class=&amp;quot;JAVA_GATEWAY_EXITED&amp;quot;,\n                        message_parameters={},\n                    )\nE                   pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.\n\nspark_env/lib/python3.11/site-packages/pyspark/java_gateway.py:107: PySparkRuntimeError\n\n---------------------------- Captured stdout setup -----------------------------\n2024-07-21T16:08:46.244796328Z main ERROR Unable to create class org.apache.logging.log4j.tojul.JULLoggerContextFactory specified in provider URL null java.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.util.LoaderUtil.newInstanceOf(LoaderUtil.java:249)\n\tat org.apache.logging.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:94)\n\tat org.apache.logging.log4j.spi.ThreadContextMapFactory.createThreadContextMap(ThreadContextMapFactory.java:113)\n\tat org.apache.logging.log4j.ThreadContext.init(ThreadContext.java:222)\n\tat org.apache.logging.log4j.ThreadContext.&amp;lt;clinit&amp;gt;(ThreadContext.java:200)\n\tat org.apache.logging.log4j.core.impl.ContextDataInjectorFactory.createDefaultInjector(ContextDataInjectorFactory.java:82)\n\tat org.apache.logging.log4j.util.LoaderUtil.newCheckedInstanceOfProperty(LoaderUtil.java:360)\n\tat org.apache.logging.log4j.core.impl.ContextDataInjectorFactory.createInjector(ContextDataInjectorFactory.java:71)\n\tat org.apache.logging.log4j.core.lookup.ContextMapLookup.&amp;lt;init&amp;gt;(ContextMapLookup.java:34)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.&amp;lt;init&amp;gt;(AbstractConfiguration.java:136)\n\tat org.apache.logging.log4j.core.config.NullConfiguration.&amp;lt;init&amp;gt;(NullConfiguration.java:32)\n\tat org.apache.logging.log4j.core.LoggerContext.&amp;lt;clinit&amp;gt;(LoggerContext.java:76)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat org.apache.log4j.LogManager.checkLog4jCore(LogManager.java:76)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:68)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.lang.IllegalStateException: log4j-jul JAR is mutually exclusive with the log4j-to-jul JAR(the first routes calls from Log4j to JUL, the second from Log4j to JUL)\n\tat org.apache.logging.log4j.tojul.JULLoggerContextFactory.&amp;lt;init&amp;gt;(JULLoggerContextFactory.java:46)\n\t... 55 more\n\n2024-07-21T16:08:46.287078127Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.&amp;lt;init&amp;gt;(AbstractConfiguration.java:136)\n\tat org.apache.logging.log4j.core.config.NullConfiguration.&amp;lt;init&amp;gt;(NullConfiguration.java:32)\n\tat org.apache.logging.log4j.core.LoggerContext.&amp;lt;clinit&amp;gt;(LoggerContext.java:76)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat org.apache.log4j.LogManager.checkLog4jCore(LogManager.java:76)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:68)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.306086927Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.&amp;lt;init&amp;gt;(AbstractConfiguration.java:136)\n\tat org.apache.logging.log4j.core.config.DefaultConfiguration.&amp;lt;init&amp;gt;(DefaultConfiguration.java:46)\n\tat org.apache.logging.log4j.core.LoggerContext.&amp;lt;init&amp;gt;(LoggerContext.java:86)\n\tat org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.createContext(ClassLoaderContextSelector.java:263)\n\tat org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:222)\n\tat org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:144)\n\tat org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:123)\n\tat org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:117)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:149)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.363201227Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:362)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:362)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;clinit&amp;gt;(ConfigurationFactory.java:135)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.368618026Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.logging.log4j.core.config.properties.PropertiesConfigurationFactory.&amp;lt;init&amp;gt;(PropertiesConfigurationFactory.java:36)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.addFactory(ConfigurationFactory.java:232)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getInstance(ConfigurationFactory.java:178)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.371384526Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.logging.log4j.core.config.yaml.YamlConfigurationFactory.&amp;lt;init&amp;gt;(YamlConfigurationFactory.java:45)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.addFactory(ConfigurationFactory.java:232)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getInstance(ConfigurationFactory.java:178)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.431079126Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.logging.log4j.core.config.json.JsonConfigurationFactory.&amp;lt;init&amp;gt;(JsonConfigurationFactory.java:44)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.addFactory(ConfigurationFactory.java:232)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getInstance(ConfigurationFactory.java:178)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.433668826Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.logging.log4j.core.config.xml.XmlConfigurationFactory.&amp;lt;init&amp;gt;(XmlConfigurationFactory.java:31)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.addFactory(ConfigurationFactory.java:232)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getInstance(ConfigurationFactory.java:178)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.437062026Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.log4j.config.PropertiesConfigurationFactory.&amp;lt;init&amp;gt;(PropertiesConfigurationFactory.java:32)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.addFactory(ConfigurationFactory.java:232)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getInstance(ConfigurationFactory.java:178)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.439555126Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:102)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.&amp;lt;init&amp;gt;(ConfigurationFactory.java:137)\n\tat org.apache.log4j.xml.XmlConfigurationFactory.&amp;lt;init&amp;gt;(XmlConfigurationFactory.java:34)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.addFactory(ConfigurationFactory.java:232)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getInstance(ConfigurationFactory.java:178)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.467951925Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:109)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.&amp;lt;init&amp;gt;(AbstractConfiguration.java:136)\n\tat org.apache.logging.log4j.core.config.builder.impl.BuiltConfiguration.&amp;lt;init&amp;gt;(BuiltConfiguration.java:53)\n\tat org.apache.logging.log4j.core.config.properties.PropertiesConfiguration.&amp;lt;init&amp;gt;(PropertiesConfiguration.java:36)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.config.builder.impl.DefaultConfigurationBuilder.build(DefaultConfigurationBuilder.java:194)\n\tat org.apache.logging.log4j.core.config.builder.impl.DefaultConfigurationBuilder.build(DefaultConfigurationBuilder.java:69)\n\tat org.apache.logging.log4j.core.config.properties.PropertiesConfigurationBuilder.build(PropertiesConfigurationBuilder.java:192)\n\tat org.apache.logging.log4j.core.config.properties.PropertiesConfigurationFactory.getConfiguration(PropertiesConfigurationFactory.java:56)\n\tat org.apache.logging.log4j.core.config.properties.PropertiesConfigurationFactory.getConfiguration(PropertiesConfigurationFactory.java:34)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:544)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:463)\n\tat org.apache.logging.log4j.core.config.ConfigurationFactory.getConfiguration(ConfigurationFactory.java:321)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:705)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n2024-07-21T16:08:46.477284525Z main ERROR Unable to create Lookup for k8s java.lang.NoSuchMethodError: &amp;#x27;long io.fabric8.kubernetes.client.Config.getRollingTimeout()&amp;#x27;\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientProperties.getRollingTimeout(KubernetesClientProperties.java:167)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.kubernetesClientConfig(KubernetesClientBuilder.java:68)\n\tat org.apache.logging.log4j.kubernetes.KubernetesClientBuilder.createClient(KubernetesClientBuilder.java:34)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.initialize(KubernetesLookup.java:87)\n\tat org.apache.logging.log4j.kubernetes.KubernetesLookup.&amp;lt;init&amp;gt;(KubernetesLookup.java:67)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n\tat org.apache.logging.log4j.core.util.ReflectionUtil.instantiate(ReflectionUtil.java:188)\n\tat org.apache.logging.log4j.core.lookup.Interpolator.&amp;lt;init&amp;gt;(Interpolator.java:90)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.doConfigure(AbstractConfiguration.java:667)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.initialize(AbstractConfiguration.java:264)\n\tat org.apache.logging.log4j.core.config.AbstractConfiguration.start(AbstractConfiguration.java:313)\n\tat org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:631)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:713)\n\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:735)\n\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:260)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:154)\n\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:46)\n\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:317)\n\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:83)\n\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:96)\n\tat org.apache.log4j.Category.&amp;lt;init&amp;gt;(Category.java:184)\n\tat org.apache.log4j.Logger.&amp;lt;init&amp;gt;(Logger.java:57)\n\tat org.apache.log4j.spi.RootLogger.&amp;lt;init&amp;gt;(RootLogger.java:38)\n\tat org.apache.log4j.LogManager.&amp;lt;clinit&amp;gt;(LogManager.java:70)\n\tat org.slf4j.impl.Log4jLoggerFactory.&amp;lt;init&amp;gt;(Log4jLoggerFactory.java:66)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;init&amp;gt;(StaticLoggerBinder.java:72)\n\tat org.slf4j.impl.StaticLoggerBinder.&amp;lt;clinit&amp;gt;(StaticLoggerBinder.java:45)\n\tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\n\tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\n\tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:417)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:362)\n\tat org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:388)\n\tat org.apache.spark.internal.SparkLoggerFactory.getLogger(SparkLoggerFactory.java:31)\n\tat org.apache.spark.network.util.JavaUtils.&amp;lt;clinit&amp;gt;(JavaUtils.java:43)\n\tat org.apache.spark.internal.config.ConfigHelpers$.byteFromString(ConfigBuilder.scala:68)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.ConfigBuilder.$anonfun$bytesConf$1$adapted(ConfigBuilder.scala:281)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.$anonfun$transform$1(ConfigBuilder.scala:102)\n\tat org.apache.spark.internal.config.TypedConfigBuilder.createWithDefault(ConfigBuilder.scala:166)\n\tat org.apache.spark.internal.config.package$.&amp;lt;clinit&amp;gt;(package.scala:441)\n\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$5(SparkSubmitArguments.scala:162)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:162)\n\tat org.apache.spark.deploy.SparkSubmitArguments.&amp;lt;init&amp;gt;(SparkSubmitArguments.scala:117)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.&amp;lt;init&amp;gt;(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1097)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:71)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n\n---------------------------- Captured stderr setup -----------------------------\nWARNING: Using incubator modules: jdk.incubator.vector\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/opt/spark/jars/slf4j-log4j12-1.7.32.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nSLF4J: A number (77) of logging calls during the initialization phase have been intercepted and are\nSLF4J: now being replayed. These are subject to the filtering rules of the underlying logging system.\nSLF4J: See also http://www.slf4j.org/codes.html#replay\nException in thread &amp;quot;main&amp;quot; org.apache.spark.SparkException: Cluster deploy mode is currently not supported for python applications on standalone clusters.\n\tat org.apache.spark.deploy.SparkSubmit.error(SparkSubmit.scala:1042)\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:296)\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958)\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:198)\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1114)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1123)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n&#34;}], &#34;S_ML/tests/test_spark_session.py::TestSparkEngine::test_run_job&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_spark_session.py::TestSparkEngine::test_run_job::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_spark_session.py::TestSparkEngine::test_run_job::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_spark_session.TestSparkEngine object at 0x7f824eef1210&amp;gt;\n\n    @pytest.fixture(scope=&amp;quot;class&amp;quot;)\n    def spark_engine(self):\n&amp;gt;       engine = SparkEngine()\n\nS_ML/tests/test_spark_session.py:9: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nS_ML/base/spark_engine.py:12: in __init__\n    .getOrCreate()\nspark_env/lib/python3.11/site-packages/pyspark/sql/session.py:497: in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\nspark_env/lib/python3.11/site-packages/pyspark/context.py:515: in getOrCreate\n    SparkContext(conf=conf or SparkConf())\nspark_env/lib/python3.11/site-packages/pyspark/context.py:201: in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\nspark_env/lib/python3.11/site-packages/pyspark/context.py:436: in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nconf = &amp;lt;pyspark.conf.SparkConf object at 0x7f824ac9d0d0&amp;gt;\npopen_kwargs = {&amp;#x27;env&amp;#x27;: {&amp;#x27;BASH_FUNC_which%%&amp;#x27;: &amp;#x27;() {  ( alias;\\n eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --rea...rk_demo/.coverage&amp;#x27;, ...}, &amp;#x27;preexec_fn&amp;#x27;: &amp;lt;function launch_gateway.&amp;lt;locals&amp;gt;.preexec_func at 0x7f824a88a020&amp;gt;, &amp;#x27;stdin&amp;#x27;: -1}\n\n    def launch_gateway(conf=None, popen_kwargs=None):\n        &amp;quot;&amp;quot;&amp;quot;\n        launch jvm gateway\n    \n        Parameters\n        ----------\n        conf : :py:class:`pyspark.SparkConf`\n            spark configuration passed to spark-submit\n        popen_kwargs : dict\n            Dictionary of kwargs to pass to Popen when spawning\n            the py4j JVM. This is a developer feature intended for use in\n            customizing how pyspark interacts with the py4j JVM (e.g., capturing\n            stdout/stderr).\n    \n        Returns\n        -------\n        ClientServer or JavaGateway\n        &amp;quot;&amp;quot;&amp;quot;\n        if &amp;quot;PYSPARK_GATEWAY_PORT&amp;quot; in os.environ:\n            gateway_port = int(os.environ[&amp;quot;PYSPARK_GATEWAY_PORT&amp;quot;])\n            gateway_secret = os.environ[&amp;quot;PYSPARK_GATEWAY_SECRET&amp;quot;]\n            # Process already exists\n            proc = None\n        else:\n            SPARK_HOME = _find_spark_home()\n            # Launch the Py4j gateway using Spark&amp;#x27;s run command so that we pick up the\n            # proper classpath and settings from spark-env.sh\n            on_windows = platform.system() == &amp;quot;Windows&amp;quot;\n            script = &amp;quot;./bin/spark-submit.cmd&amp;quot; if on_windows else &amp;quot;./bin/spark-submit&amp;quot;\n            command = [os.path.join(SPARK_HOME, script)]\n            if conf:\n                for k, v in conf.getAll():\n                    command += [&amp;quot;--conf&amp;quot;, &amp;quot;%s=%s&amp;quot; % (k, v)]\n            submit_args = os.environ.get(&amp;quot;PYSPARK_SUBMIT_ARGS&amp;quot;, &amp;quot;pyspark-shell&amp;quot;)\n            if os.environ.get(&amp;quot;SPARK_TESTING&amp;quot;):\n                submit_args = &amp;quot; &amp;quot;.join([&amp;quot;--conf spark.ui.enabled=false&amp;quot;, submit_args])\n            command = command + shlex.split(submit_args)\n    \n            # Create a temporary directory where the gateway server should write the connection\n            # information.\n            conn_info_dir = tempfile.mkdtemp()\n            try:\n                fd, conn_info_file = tempfile.mkstemp(dir=conn_info_dir)\n                os.close(fd)\n                os.unlink(conn_info_file)\n    \n                env = dict(os.environ)\n                env[&amp;quot;_PYSPARK_DRIVER_CONN_INFO_PATH&amp;quot;] = conn_info_file\n    \n                # Launch the Java gateway.\n                popen_kwargs = {} if popen_kwargs is None else popen_kwargs\n                # We open a pipe to stdin so that the Java gateway can die when the pipe is broken\n                popen_kwargs[&amp;quot;stdin&amp;quot;] = PIPE\n                # We always set the necessary environment variables.\n                popen_kwargs[&amp;quot;env&amp;quot;] = env\n                if not on_windows:\n                    # Don&amp;#x27;t send ctrl-c / SIGINT to the Java gateway:\n                    def preexec_func():\n                        signal.signal(signal.SIGINT, signal.SIG_IGN)\n    \n                    popen_kwargs[&amp;quot;preexec_fn&amp;quot;] = preexec_func\n                    proc = Popen(command, **popen_kwargs)\n                else:\n                    # preexec_fn not supported on Windows\n                    proc = Popen(command, **popen_kwargs)\n    \n                # Wait for the file to appear, or for the process to exit, whichever happens first.\n                while not proc.poll() and not os.path.isfile(conn_info_file):\n                    time.sleep(0.1)\n    \n                if not os.path.isfile(conn_info_file):\n&amp;gt;                   raise PySparkRuntimeError(\n                        error_class=&amp;quot;JAVA_GATEWAY_EXITED&amp;quot;,\n                        message_parameters={},\n                    )\nE                   pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.\n\nspark_env/lib/python3.11/site-packages/pyspark/java_gateway.py:107: PySparkRuntimeError\n&#34;}], &#34;S_ML/tests/test_spark_session.py::TestSparkEngine::test_stop&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;S_ML/tests/test_spark_session.py::TestSparkEngine::test_stop::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;S_ML/tests/test_spark_session.py::TestSparkEngine::test_stop::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_spark_session.TestSparkEngine object at 0x7f824eef1210&amp;gt;\n\n    @pytest.fixture(scope=&amp;quot;class&amp;quot;)\n    def spark_engine(self):\n&amp;gt;       engine = SparkEngine()\n\nS_ML/tests/test_spark_session.py:9: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nS_ML/base/spark_engine.py:12: in __init__\n    .getOrCreate()\nspark_env/lib/python3.11/site-packages/pyspark/sql/session.py:497: in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\nspark_env/lib/python3.11/site-packages/pyspark/context.py:515: in getOrCreate\n    SparkContext(conf=conf or SparkConf())\nspark_env/lib/python3.11/site-packages/pyspark/context.py:201: in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\nspark_env/lib/python3.11/site-packages/pyspark/context.py:436: in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nconf = &amp;lt;pyspark.conf.SparkConf object at 0x7f824ac9d0d0&amp;gt;\npopen_kwargs = {&amp;#x27;env&amp;#x27;: {&amp;#x27;BASH_FUNC_which%%&amp;#x27;: &amp;#x27;() {  ( alias;\\n eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --rea...rk_demo/.coverage&amp;#x27;, ...}, &amp;#x27;preexec_fn&amp;#x27;: &amp;lt;function launch_gateway.&amp;lt;locals&amp;gt;.preexec_func at 0x7f824a88a020&amp;gt;, &amp;#x27;stdin&amp;#x27;: -1}\n\n    def launch_gateway(conf=None, popen_kwargs=None):\n        &amp;quot;&amp;quot;&amp;quot;\n        launch jvm gateway\n    \n        Parameters\n        ----------\n        conf : :py:class:`pyspark.SparkConf`\n            spark configuration passed to spark-submit\n        popen_kwargs : dict\n            Dictionary of kwargs to pass to Popen when spawning\n            the py4j JVM. This is a developer feature intended for use in\n            customizing how pyspark interacts with the py4j JVM (e.g., capturing\n            stdout/stderr).\n    \n        Returns\n        -------\n        ClientServer or JavaGateway\n        &amp;quot;&amp;quot;&amp;quot;\n        if &amp;quot;PYSPARK_GATEWAY_PORT&amp;quot; in os.environ:\n            gateway_port = int(os.environ[&amp;quot;PYSPARK_GATEWAY_PORT&amp;quot;])\n            gateway_secret = os.environ[&amp;quot;PYSPARK_GATEWAY_SECRET&amp;quot;]\n            # Process already exists\n            proc = None\n        else:\n            SPARK_HOME = _find_spark_home()\n            # Launch the Py4j gateway using Spark&amp;#x27;s run command so that we pick up the\n            # proper classpath and settings from spark-env.sh\n            on_windows = platform.system() == &amp;quot;Windows&amp;quot;\n            script = &amp;quot;./bin/spark-submit.cmd&amp;quot; if on_windows else &amp;quot;./bin/spark-submit&amp;quot;\n            command = [os.path.join(SPARK_HOME, script)]\n            if conf:\n                for k, v in conf.getAll():\n                    command += [&amp;quot;--conf&amp;quot;, &amp;quot;%s=%s&amp;quot; % (k, v)]\n            submit_args = os.environ.get(&amp;quot;PYSPARK_SUBMIT_ARGS&amp;quot;, &amp;quot;pyspark-shell&amp;quot;)\n            if os.environ.get(&amp;quot;SPARK_TESTING&amp;quot;):\n                submit_args = &amp;quot; &amp;quot;.join([&amp;quot;--conf spark.ui.enabled=false&amp;quot;, submit_args])\n            command = command + shlex.split(submit_args)\n    \n            # Create a temporary directory where the gateway server should write the connection\n            # information.\n            conn_info_dir = tempfile.mkdtemp()\n            try:\n                fd, conn_info_file = tempfile.mkstemp(dir=conn_info_dir)\n                os.close(fd)\n                os.unlink(conn_info_file)\n    \n                env = dict(os.environ)\n                env[&amp;quot;_PYSPARK_DRIVER_CONN_INFO_PATH&amp;quot;] = conn_info_file\n    \n                # Launch the Java gateway.\n                popen_kwargs = {} if popen_kwargs is None else popen_kwargs\n                # We open a pipe to stdin so that the Java gateway can die when the pipe is broken\n                popen_kwargs[&amp;quot;stdin&amp;quot;] = PIPE\n                # We always set the necessary environment variables.\n                popen_kwargs[&amp;quot;env&amp;quot;] = env\n                if not on_windows:\n                    # Don&amp;#x27;t send ctrl-c / SIGINT to the Java gateway:\n                    def preexec_func():\n                        signal.signal(signal.SIGINT, signal.SIG_IGN)\n    \n                    popen_kwargs[&amp;quot;preexec_fn&amp;quot;] = preexec_func\n                    proc = Popen(command, **popen_kwargs)\n                else:\n                    # preexec_fn not supported on Windows\n                    proc = Popen(command, **popen_kwargs)\n    \n                # Wait for the file to appear, or for the process to exit, whichever happens first.\n                while not proc.poll() and not os.path.isfile(conn_info_file):\n                    time.sleep(0.1)\n    \n                if not os.path.isfile(conn_info_file):\n&amp;gt;                   raise PySparkRuntimeError(\n                        error_class=&amp;quot;JAVA_GATEWAY_EXITED&amp;quot;,\n                        message_parameters={},\n                    )\nE                   pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.\n\nspark_env/lib/python3.11/site-packages/pyspark/java_gateway.py:107: PySparkRuntimeError\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>